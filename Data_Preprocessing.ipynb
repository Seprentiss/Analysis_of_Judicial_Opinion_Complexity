{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3vyadGe9IsC"
      },
      "outputs": [],
      "source": [
        "# check gpu connection\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "agXCYQSY9Wip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "id": "h3qu6uxl9X_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "IXLP8cAs9YpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This block converts pdf's into pandas dataframe as a string\n",
        "start = time.time()\n",
        "\n",
        "def get_filepaths(directory):\n",
        "  \n",
        "    \"\"\"\n",
        "    This function will generate the file names in a directory \n",
        "    tree by walking the tree either top-down or bottom-up. For each \n",
        "    directory in the tree rooted at directory top (including top itself), \n",
        "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
        "    \"\"\"\n",
        "    file_paths = []  # List which will store all of the full filepaths.\n",
        "\n",
        "    # Walk the tree.\n",
        "    for root, directories, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            # Join the two strings in order to form the full filepath.\n",
        "            filepath = os.path.join(root, filename)\n",
        "            file_paths.append(filepath)  # Add it to the list.\n",
        "\n",
        "    return file_paths  # Self-explanatory.\n"
      ],
      "metadata": {
        "id": "dr77PWP39aww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find case_id\n",
        "def find_case_id(file_array,file_index):\n",
        "  with tf.device('/device:GPU:0'):  \n",
        "    name = (file_array[file_index].split('/')[6])\n",
        "    case_id_temp = name.split('-')\n",
        "    case_id = case_id_temp[2] + \"-\" + case_id_temp[3]\n",
        "    case_problem_identifier = case_id_temp[4][0]\n",
        "\n",
        "    return case_id,case_problem_identifier\n",
        "\n",
        "# Loop through all pages in pdf file\n",
        "# **ADDING Extracting the judges name from the first page\n",
        "def loop(file):\n",
        "  with tf.device('/device:GPU:0'):  \n",
        "    text = \"\"\n",
        "    for page in range(len(file.pages)):\n",
        "            text += file.pages[page].extract_text()\n",
        "\n",
        "    return text "
      ],
      "metadata": {
        "id": "Yu0E5mVJ-Qpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# run with gpu\n",
        "with tf.device('/device:GPU:0'):  \n",
        "\n",
        "  # court that we want to convert to csv\n",
        "  court_nums = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "\n",
        "  for court in court_nums:\n",
        "\n",
        "\n",
        "    files = get_filepaths(\"/content/gdrive/MyDrive/CS_490_DATA/Court_\"+str(court))\n",
        "\n",
        "\n",
        "    # randomly select a subset of 1000 files\n",
        "    files = np.random.choice(files, 1000, replace= False)\n",
        "\n",
        "    data = pd.DataFrame(columns=['Court_id','Case_id',\"Opinion\"])   #Added judges here - took out\n",
        "\n",
        "    count = 0\n",
        "    completed_count = 0\n",
        "\n",
        "    # loop through all files in directory\n",
        "    for file in files:\n",
        "      if completed_count == 500:\n",
        "          break;\n",
        "      with tf.device('/device:GPU:0'):  \n",
        "        with pdfplumber.open(file) as f:\n",
        "            case_id, case_problem_id = find_case_id(count)\n",
        "            if len(f.pages) < 2 or case_problem_id == 1:\n",
        "              count+=1\n",
        "              print(count)\n",
        "              continue\n",
        "            all_text = loop(f)\n",
        "            data.loc[len(data.index)] = [court, case_id ,all_text]\n",
        "        completed_count +=1\n",
        "        count+=1\n",
        "        # keep track of where we are\n",
        "        print(count)\n",
        "        # In case process crashes we have some data that is cleaned, so we don't need to completely restart\n",
        "        data.to_csv(\"/content/gdrive/MyDrive/CS_490_DATA/Court_\"+str(court)+\".csv\")\n",
        "    \n",
        "    # Convert data to csv\n",
        "    data.to_csv(\"/content/gdrive/MyDrive/CS_490_DATA/Court_\"+str(court)+\".csv\")\n",
        "\n",
        "\n",
        "    end = time.time()\n",
        "    print(end-start)"
      ],
      "metadata": {
        "id": "3QPJHymd9-ge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}