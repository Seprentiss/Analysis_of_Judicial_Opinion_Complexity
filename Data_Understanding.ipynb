{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nrd8QuzPVg7"
      },
      "outputs": [],
      "source": [
        "# check gpu connection\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILNWQWkNqyC3"
      },
      "outputs": [],
      "source": [
        "# connect to drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RD35TND-w72"
      },
      "outputs": [],
      "source": [
        "pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taOPj88GSfho"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-7k0HMvqyqa"
      },
      "outputs": [],
      "source": [
        "# This block converts pdf's into pandas dataframe as a string\n",
        "start = time.time()\n",
        "\n",
        "def get_filepaths(directory):\n",
        "  \n",
        "    \"\"\"\n",
        "    This function will generate the file names in a directory \n",
        "    tree by walking the tree either top-down or bottom-up. For each \n",
        "    directory in the tree rooted at directory top (including top itself), \n",
        "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
        "    \"\"\"\n",
        "    file_paths = []  # List which will store all of the full filepaths.\n",
        "\n",
        "    # Walk the tree.\n",
        "    for root, directories, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            # Join the two strings in order to form the full filepath.\n",
        "            filepath = os.path.join(root, filename)\n",
        "            file_paths.append(filepath)  # Add it to the list.\n",
        "\n",
        "    return file_paths  # Self-explanatory.\n",
        "\n",
        "# run with gpu\n",
        "with tf.device('/device:GPU:0'):  \n",
        "\n",
        "  # court that we want to convert to csv\n",
        "  court_nums = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "\n",
        "  files = get_filepaths(\"/content/gdrive/MyDrive/CS_490_DATA/Court_\"+str(court_num))\n",
        "\n",
        "\n",
        "  # randomly select a subset of files\n",
        "  files = np.random.choice(files, 1000, replace= False)\n",
        "\n",
        "  # Find case_id\n",
        "  def find_case_id(file_index):\n",
        "    name = (files[count].split('/')[6])\n",
        "    case_id_temp = name.split('-')\n",
        "    case_id = case_id_temp[2] + \"-\" + case_id_temp[3]\n",
        "    case_problem_identifier = case_id_temp[4][0]\n",
        "\n",
        "    return case_id,case_problem_identifier\n",
        "\n",
        "  # Loop through all pages in pdf file\n",
        "  # **ADDING Extracting the judges name from the first page\n",
        "  def loop(file):\n",
        "    with tf.device('/device:GPU:0'):  \n",
        "      text = \"\"\n",
        "      for page in range(len(file.pages)):\n",
        "              text += file.pages[page].extract_text()\n",
        "\n",
        "      #For court 11 only\n",
        "      #regDOTALL = re.compile(r'\\bBefore\\b.*\\bJudges\\b\\.', re.DOTALL)\n",
        "      #judge_line = regDOTALL.findall(text)\n",
        "      #judges_list = re.findall(r'(\\b[A-Z]+\\b\\s\\b[A-Z]+\\b|\\b[A-Z]+\\b)', judge_line[0])\n",
        "      # Not sure how we want to store judges, each in own column?, as a list?,\n",
        "      # just as another string with all of them concatenated?\n",
        "\n",
        "      return text    #, judges_list - took out\n",
        "\n",
        "  # Make new function for judges?\n",
        "  # For court 11, format is: Before ED CARNES, Chief Judge, MARTIN, and ROSENBAUM, Circuit Judges.\n",
        "  # So usually: Before JUDGE_FIRST JUDGE_LAST, Chief Judge, JUDGE2_LAST, and JUDGE3_LAST, Circuit Judges.\n",
        "  # Always starts with \"Before\", sometimes no \"and\", names always in caps, always separated\n",
        "  # by commas, and typically ends with \"Judge(s).\"\n",
        "  \n",
        "\n",
        "  data = pd.DataFrame(columns=['Court_id','Case_id',\"Opinion\"])   #Added judges here - took out\n",
        "\n",
        "  count = 0\n",
        "  completed_count = 0\n",
        "\n",
        "  # loop through all files in directory\n",
        "  for file in files:\n",
        "    if completed_count == 500:\n",
        "        break;\n",
        "    with tf.device('/device:GPU:0'):  \n",
        "      with pdfplumber.open(file) as f:\n",
        "          case_id, case_problem_id = find_case_id(count)\n",
        "          if len(f.pages) < 2 or case_problem_id == 1:\n",
        "            count+=1\n",
        "            print(count)\n",
        "            continue\n",
        "          all_text = loop(f)\n",
        "          data.loc[len(data.index)] = [court_num, case_id ,all_text]  # Added judges column - took out\n",
        "      completed_count +=1\n",
        "      count+=1\n",
        "      # keep track of where we are\n",
        "      print(count)\n",
        "      data.to_csv(\"/content/gdrive/MyDrive/CS_490_DATA/Court_\"+str(court_num)+\".csv\")\n",
        "  \n",
        "  # Convert data to csv\n",
        "  data.to_csv(\"/content/gdrive/MyDrive/CS_490_DATA/Court_\"+str(court_num)+\".csv\")\n",
        "\n",
        "\n",
        "  end = time.time()\n",
        "  print(end-start)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VhBrXU-qI_Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHg_HOblBOj8"
      },
      "outputs": [],
      "source": [
        "# Code to get number of pages/files\n",
        "\n",
        "from pdfplumber import pdf\n",
        "def get_filepaths(directory):\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    file_paths = []  # List which will store all of the full filepaths.\n",
        "    # Walk the tree.\n",
        "    for root, directories, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            # Join the two strings in order to form the full filepath.\n",
        "            filepath = os.path.join(root, filename)\n",
        "            file_paths.append(filepath)  # Add it to the list.\n",
        "\n",
        "    return file_paths  # Self-explanatory.\n",
        "\n",
        "def number_of_pages(file):\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    with pdfplumber.open(file) as f:\n",
        "        return len(f.pages)\n",
        "\n",
        "# list all court that you want included\n",
        "court_num = [2]\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  for num in court_num:\n",
        "    sum = 0\n",
        "    lenOne_pages = 0\n",
        "    file_paths = get_filepaths(\"/content/gdrive/MyDrive/CS_490_DATA/Court_\"+str(num))\n",
        "    for file in file_paths:\n",
        "      num_pages = number_of_pages(file)\n",
        "      if num_pages == 1:\n",
        "        lenOne_pages += 1\n",
        "      sum+= num_pages\n",
        "    print(\"COURT_\"+str(num) + \":\" + str(len(file_paths)) + \" Total Opionions\")\n",
        "    print(\"COURT_\"+str(num) + \":\" + str(sum) + \" Pages\")\n",
        "    print(\"COURT_\"+str(num) + \":\" + str(lenOne_pages) + \" Pages\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/CS_490_DATA/Court_8.csv\")\n",
        "\n",
        "text = \" \".join(review for review in data[\"Opinion\"])\n",
        "\n",
        "text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') "
      ],
      "metadata": {
        "id": "8CJhdvXRlv2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0215e70-9314-473e-c4fe-47ceec2d8cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "with tf.device('/device:GPU:0'):  \n",
        "  text_tokens = word_tokenize(text)\n",
        "  tokens_without_sw = [word for word in text_tokens if not word in stopwords.words(\"english\")]\n",
        "  "
      ],
      "metadata": {
        "id": "DZMc6_mul_Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "  \n",
        "  \n",
        "# split() returns list of all the words in the string\n",
        "  \n",
        "# Pass the split_it list to instance of Counter class.\n",
        "Counter = Counter(tokens_without_sw)\n",
        "  \n",
        "# most_common() produces k frequently encountered\n",
        "# input values and their respective counts.\n",
        "most_occur = Counter.most_common(1000)\n",
        "  \n",
        "print(most_occur)"
      ],
      "metadata": {
        "id": "6XveJ7h3nPaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a0137e-b60e-4ab3-8eb1-42876ff3c70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('v', 4498), ('court', 3312), ('The', 3236), ('States', 3172), ('United', 3167), ('F3d', 2644), ('district', 2625), ('Filed', 2604), ('Appellate', 2379), ('Case', 2367), ('Cir', 2356), ('Date', 2249), ('Page', 2233), ('Entry', 2231), ('ID', 2231), ('8th', 2095), ('District', 1717), ('See', 1619), ('Court', 1543), ('____________', 1483), ('Mr', 1345), ('2', 1221), ('evidence', 1186), ('Circuit', 1174), ('In', 1038), ('We', 1035), ('judgment', 1028), ('also', 1027), ('US', 1013), ('sentence', 978), ('appeal', 976), ('would', 929), ('___________________________', 919), ('1', 888), ('review', 864), ('claim', 816), ('law', 805), ('courts', 803), ('No', 792), ('case', 768), ('USC', 748), ('must', 732), ('et', 726), ('al', 709), ('whether', 700), ('Id', 695), ('Eighth', 687), ('Missouri', 680), ('may', 664), ('For', 662), ('3', 662), ('motion', 648), ('A', 634), ('2020', 628), ('opinion', 621), ('Appeals', 608), ('Judge', 605), ('claims', 601), ('see', 600), ('record', 592), ('within', 572), ('time', 572), ('filed', 570), ('one', 569), ('reasonable', 564), ('Ms', 562), ('found', 554), ('petitions', 545), ('two', 527), ('Inc', 521), ('rehearing', 516), ('offense', 495), ('2021', 480), ('state', 475), ('discretion', 466), ('4', 465), ('Michael', 464), ('defendant', 461), ('could', 456), ('Iowa', 452), ('banc', 438), ('sentencing', 421), ('conclude', 420), ('Appellant', 419), ('Before', 419), ('error', 415), ('factors', 413), ('decision', 405), ('received', 404), ('en', 404), ('argues', 397), ('Judges', 395), ('18', 393), ('drug', 392), ('Appellee', 388), ('trial', 385), ('affirm', 385), ('jury', 384), ('5', 384), ('Company', 383), ('bankruptcy', 383), ('based', 381), ('denied', 380), ('petition', 378), ('E', 377), ('Submitted', 371), ('period', 370), ('waiver', 368), ('2019', 366), ('officers', 364), ('agreement', 362), ('conduct', 357), ('order', 356), ('______________________________', 355), ('contract', 351), ('Honorable', 350), ('counsel', 350), ('filing', 347), ('issue', 346), ('14', 345), ('government', 344), ('summary', 344), ('abuse', 343), ('3M', 341), ('I', 337), ('parties', 337), ('finding', 335), ('defendants', 334), ('Appeal', 333), ('8', 331), ('plea', 331), ('omitted', 328), ('2018', 327), ('damages', 327), ('7', 323), ('months', 321), ('date', 321), ('action', 320), ('grant', 318), ('quoting', 317), ('failed', 316), ('required', 316), ('entered', 312), ('made', 311), ('relevant', 310), ('This', 309), ('6', 309), ('America', 308), ('1The', 307), ('Ct', 306), ('fact', 306), ('As', 306), ('testimony', 304), ('standard', 304), ('guilty', 301), ('City', 300), ('Mo', 300), ('first', 299), ('S', 287), ('alleged', 286), ('federal', 285), ('violation', 282), ('Guidelines', 282), ('Act', 281), ('R', 279), ('Clerk', 279), ('lllllllllllllllllllllDefendant', 278), ('issues', 278), ('appeals', 277), ('withdraw', 277), ('even', 277), ('firearm', 277), ('public', 275), ('without', 274), ('clear', 274), ('St', 274), ('Co', 273), ('de', 271), ('314', 271), ('support', 267), ('find', 265), ('right', 265), ('Rules', 265), ('novo', 264), ('information', 262), ('But', 262), ('F', 262), ('argument', 260), ('11', 258), ('lllllllllllllllllllllPlaintiff', 257), ('Gans', 256), ('cause', 256), ('Please', 255), ('release', 255), ('facts', 254), ('Western', 254), ('Street', 254), ('range', 253), ('He', 252), ('court1', 251), ('show', 251), ('It', 251), ('search', 251), ('PER', 250), ('CURIAM', 250), ('On', 249), ('Louis', 249), ('Unpublished', 247), ('testified', 244), ('cases', 244), ('including', 243), ('2017', 243), ('person', 242), ('criminal', 241), ('consider', 239), ('three', 239), ('statute', 237), ('days', 237), ('imposed', 236), ('Minnesota', 234), ('Federal', 234), ('2016', 233), ('brief', 233), ('relief', 231), ('part', 230), ('State', 230), ('use', 229), ('Accordingly', 229), ('First', 229), ('unreasonable', 229), ('Arkansas', 229), ('used', 228), ('day', 227), ('methamphetamine', 224), ('erred', 223), ('9', 223), ('officer', 222), ('After', 221), ('considered', 220), ('clearly', 220), ('question', 219), ('2009', 219), ('2014', 217), ('reviewed', 217), ('M', 217), ('fees', 215), ('10', 214), ('complaint', 214), ('circumstances', 213), ('factual', 213), ('legal', 212), ('interest', 212), ('matter', 210), ('conviction', 208), ('allowed', 208), ('work', 208), ('possession', 206), ('Amendment', 206), ('sufficient', 205), ('party', 203), ('SW3d', 201), ('denial', 199), ('substantial', 199), ('imprisonment', 198), ('new', 198), ('2015', 198), ('LLC', 198), ('D', 197), ('due', 196), ('held', 195), ('irrelevant', 195), ('Williams', 193), ('award', 193), ('moved', 193), ('amount', 192), ('At', 192), ('policy', 192), ('result', 191), ('basis', 190), ('breach', 190), ('issued', 189), ('supervised', 189), ('Debtors', 189), ('Thomas', 188), ('prior', 188), ('years', 187), ('another', 185), ('13', 185), ('Procedure', 184), ('Rule', 183), ('hold', 183), ('term', 182), ('provided', 181), ('When', 181), ('conspiracy', 180), ('Johnson', 180), ('California', 180), ('plan', 180), ('concluded', 179), ('And', 179), ('hearing', 179), ('jurisdiction', 179), ('plaintiffs', 179), ('establish', 178), ('Because', 178), ('South', 178), ('Supreme', 177), ('drivers', 174), ('provide', 174), ('today', 174), ('statutory', 173), ('stated', 172), ('id', 172), ('entitled', 172), ('different', 171), ('findings', 170), ('12', 169), ('rules', 168), ('L', 168), ('request', 167), ('USSG', 167), ('removal', 167), ('factor', 167), ('rights', 167), ('drugs', 166), ('released', 166), ('purpose', 166), ('Officer', 166), ('CRST', 166), ('To', 165), ('timely', 165), ('J', 165), ('2012', 164), ('NW2d', 164), ('determination', 164), ('permitted', 164), ('2011', 163), ('notice', 163), ('particularly', 163), ('need', 162), ('children', 162), ('compliance', 162), ('Eastern', 162), ('prison', 162), ('police', 162), ('entry', 160), ('1000', 160), ('conditions', 160), ('child', 159), ('2013', 159), ('appropriate', 159), ('15', 158), ('Chief', 158), ('level', 158), ('intent', 158), ('fee', 158), ('2010', 157), ('scope', 157), ('10th', 157), ('21', 156), ('proceedings', 156), ('28', 156), ('III', 155), ('February', 155), ('second', 155), ('Southern', 155), ('false', 154), ('enhancement', 154), ('section', 154), ('presented', 154), ('40', 154), ('provision', 154), ('upon', 153), ('App', 153), ('April', 152), ('light', 152), ('citation', 152), ('individual', 152), ('pleaded', 152), ('properly', 152), ('granted', 152), ('John', 151), ('Any', 151), ('Counsel', 150), ('ensure', 149), ('distribute', 148), ('home', 148), ('later', 147), ('explained', 147), ('sentenced', 147), ('procedure', 147), ('address', 147), ('known', 146), ('committed', 146), ('reasons', 146), ('however', 146), ('said', 145), ('office', 145), ('3553a', 145), ('terms', 145), ('2008', 144), ('particular', 144), ('Judgment', 144), ('determined', 144), ('process', 144), ('material', 144), ('trust', 144), ('accordance', 143), ('B', 143), ('established', 143), ('Ackerman', 143), ('substantive', 142), ('err', 142), ('Board', 142), ('explaining', 142), ('leave', 142), ('Anders', 142), ('post', 142), ('significant', 142), ('conclusion', 141), ('reasonableness', 141), ('arrest', 141), ('make', 140), ('per', 140), ('determine', 140), ('apply', 140), ('pursuant', 140), ('dismiss', 139), ('June', 138), ('payment', 138), ('burden', 138), ('separate', 138), ('services', 138), ('untimely', 138), ('January', 138), ('Corp', 138), ('health', 138), ('qualified', 137), ('analysis', 137), ('determining', 137), ('submission', 137), ('history', 137), ('involved', 136), ('contemplated', 136), ('Note', 136), ('present', 135), ('Stat', 135), ('16', 135), ('arguments', 135), ('substantively', 135), ('applied', 134), ('crime', 134), ('pay', 134), ('mailing', 134), ('Miller', 134), ('II', 133), ('P', 133), ('quotation', 133), ('F2d', 133), ('electronically', 133), ('liability', 133), ('told', 132), ('agree', 132), ('August', 132), ('therefore', 132), ('111', 132), ('copies', 132), ('thus', 132), ('duty', 132), ('probable', 132), ('improper', 132), ('DL', 132), ('March', 131), ('property', 131), ('gun', 131), ('medical', 131), ('Courthouse', 130), ('confidence', 130), ('Paper', 130), ('clerks', 129), ('violated', 129), ('Brown', 129), ('challenges', 128), ('noted', 128), ('substance', 128), ('Defendants', 128), ('Although', 128), ('Eagleton', 128), ('Room', 128), ('24329', 128), ('63102', 128), ('VOICE', 128), ('2442400', 128), ('FAX', 128), ('2442780', 128), ('wwwca8uscourtsgov', 128), ('RE', 128), ('Dear', 128), ('Counselfiled', 128), ('CMECF', 128), ('grace', 128), ('postmark', 128), ('prosefiled', 128), ('FRAP', 128), ('Enclosures', 128), ('cc', 128), ('CourtAgency', 128), ('Numbers', 128), ('affirmed', 128), ('employment', 128), ('offenses', 127), ('constitutional', 127), ('May', 127), ('statement', 127), ('Fed', 127), ('December', 127), ('reasonably', 126), ('actual', 126), ('2007', 126), ('interpretation', 126), ('weight', 126), ('report', 126), ('controlled', 125), ('account', 125), ('actions', 125), ('parents', 125), ('rather', 124), ('STRAS', 124), ('2003', 124), ('care', 124), ('DLs', 124), ('denying', 123), ('shall', 123), ('holding', 123), ('1988', 123), ('cocaine', 123), ('immunity', 123), ('Pharmacies', 123), ('either', 122), ('October', 122), ('official', 122), ('well', 121), ('BIA', 121), ('favor', 121), ('738', 121), ('Dakota', 121), ('injury', 121), ('dismissed', 120), ('reason', 120), ('challenge', 120), ('20', 120), ('Scott', 120), ('Fourth', 120), ('failure', 120), ('caused', 120), ('asked', 119), ('Ohio', 119), ('ERICKSON', 118), ('business', 118), ('2006', 118), ('provides', 118), ('C', 118), ('Second', 118), ('certain', 118), ('488', 118), ('386', 118), ('distribution', 118), ('give', 118), ('enforcement', 118), ('set', 117), ('persecution', 117), ('point', 117), ('original', 117), ('NPS', 117), ('prove', 116), ('September', 116), ('extent', 116), ('limited', 116), ('authority', 116), ('requires', 116), ('42', 116), ('included', 116), ('Smith', 115), ('application', 115), ('agreed', 115), ('She', 114), ('number', 114), ('contends', 114), ('felony', 114), ('necessary', 114), ('condition', 114), ('activity', 113), ('Under', 113), ('Department', 113), ('us', 113), ('75', 113), ('likely', 113), ('fraud', 113), ('2005', 112), ('remand', 112), ('rule', 112), ('1967', 112), ('David', 112), ('like', 112), ('sex', 112), ('However', 111), ('statements', 111), ('require', 111), ('plaintiff', 111), ('take', 111), ('least', 110), ('insufficient', 110), ('include', 110), ('If', 110), ('Appellants', 110), ('Here', 110), ('direct', 110), ('money', 109), ('specific', 109), ('concluding', 109), ('vehicle', 109), ('next', 109), ('judge', 109), ('knew', 108), ('argue', 108), ('Penson', 108), ('related', 108), ('plain', 108), ('risk', 108), ('Bankruptcy', 108), ('KELLY', 107), ('car', 107), ('phone', 107), ('arguing', 107), ('lack', 107), ('Kansas', 107), ('nonfrivolous', 107), ('reduction', 107), ('records', 106), ('paid', 106), ('Appellees', 106), ('SHEPHERD', 106), ('language', 106), ('Bad', 106), ('several', 105), ('charge', 105), ('provisions', 105), ('Finally', 105), ('regarding', 105), ('supports', 105), ('Plaintiff', 105), ('general', 105), ('Ahmed', 105), ('convictions', 104), ('Immigration', 104), ('CFR', 104), ('capacity', 104), ('There', 103), ('additional', 103), ('independently', 103), ('marks', 102), ('GRASZ', 102), ('counsels', 102), ('Robert', 102), ('Defendant', 102), ('curiam', 102), ('contracts', 102), ('insurance', 102), ('school', 102), ('November', 101), ('marijuana', 101), ('following', 101), ('internal', 101), ('citing', 101), ('subject', 101), ('admitted', 101), ('residence', 101), ('Suite', 101), ('Section', 101), ('Jr', 101), ('dispute', 101), ('allegations', 101), ('purposes', 100), ('IJ', 100), ('never', 100), ('His', 100), ('knowingly', 100), ('outside', 100), ('given', 100), ('interference', 100), ('Haynes', 100), ('BENTON', 99), ('reviewing', 99), ('element', 98), ('emphasis', 98), ('While', 98), ('Minn', 98), ('Ins', 98), ('stop', 98), ('sentences', 97), ('applies', 97), ('proof', 97), ('group', 97), ('1983', 97), ('defense', 97), ('W', 97), ('Ferguson', 97), ('confusion', 97), ('house', 96), ('acts', 96), ('Order', 96), ('left', 96), ('LOKEN', 96), ('TransAm', 96), ('Health', 96), ('PNC', 96), ('final', 95), ('place', 95), ('less', 95), ('might', 95), ('COLLOTON', 95), ('Step', 95), ('Having', 95), ('That', 95), ('Haley', 95), ('eg', 94), ('four', 94), ('stating', 94), ('raised', 94), ('expert', 94), ('Bank', 94), ('GRUENDER', 93), ('added', 93), ('similar', 93), ('attorneys', 93), ('se', 93), ('Code', 93), ('SMI', 93), ('premises', 93), ('Allegiant', 93), ('Donelson', 93), ('attorney', 92), ('special', 92), ('proper', 92), ('file', 92), ('policies', 92), ('grams', 91), ('convicted', 91), ('challenging', 91), ('loss', 91), ('Tanner', 91), ('They', 90), ('base', 90), ('course', 90), ('dismissal', 90), ('applying', 90), ('careful', 90), ('fails', 90), ('trusts', 90), ('motions', 89), ('underlying', 89), ('social', 89), ('County', 89), ('SW2d', 89), ('Even', 89), ('benefits', 89), ('XPO', 89), ('administrative', 89), ('consistent', 88), ('deny', 88), ('Thus', 88), ('noting', 88), ('pro', 88), ('voluntarily', 88), ('17', 88), ('Jones', 88), ('July', 87), ('means', 87), ('shows', 87), ('argued', 87), ('questions', 87), ('Plaintiffs', 87), ('placed', 87), ('treatment', 87), ('obligations', 87), ('theory', 87), ('force', 87), ('charged', 86), ('cmt', 86), ('otherwise', 86), ('asserts', 86), ('North', 86), ('protected', 86), ('Sentencing', 85), ('five', 85), ('identified', 85), ('trustee', 85), ('debt', 85), ('municipalities', 85), ('transmission', 85), ('gave', 84), ('verdict', 84), ('nature', 84), ('investigation', 84), ('states', 84), ('Boy', 84), ('applicable', 84), ('Police', 84), ('began', 83), ('costs', 83), ('elements', 83), ('30', 83), ('sought', 83), ('advisory', 83), ('warrant', 83), ('containing', 82), ('way', 82), ('2004', 82), ('24', 82), ('multiple', 82), ('forth', 82), ('requirement', 82), ('test', 82), ('intentional', 82), ('LundRoss', 82), ('occurred', 81), ('cleaned', 81), ('still', 81), ('KOBES', 81), ('decided', 81), ('true', 81), ('available', 81), ('others', 80), ('unless', 80), ('judicial', 80), ('weighing', 80), ('Moore', 80), ('room', 80), ('Walmart', 80), ('quantity', 79), ('reverse', 79), ('believe', 79), ('context', 79), ('James', 79), ('good', 79), ('generally', 79), ('Chapter', 79), ('pharmacy', 79), ('trade', 79), ('Davis', 79), ('DNA', 79), ('WOLLMAN', 78), ('Further', 78), ('connection', 78), ('stay', 78), ('payments', 77), ('agency', 77), ('decisions', 77), ('exercise', 77), ('violations', 77), ('adverse', 77), ('Upon', 77), ('violence', 77), ('act', 77), ('patients', 77), ('Bivens', 77), ('McReynolds', 77), ('Madison', 77), ('role', 76), ('meaning', 76), ('2002', 76), ('impose', 76), ('initial', 76), ('liable', 76), ('dangerous', 76), ('serious', 76), ('though', 76), ('Agreement', 76), ('Ackermans', 76), ('times', 75), ('572', 75), ('harm', 75), ('Northern', 75), ('23', 75), ('potential', 75), ('coverage', 75), ('specifically', 74), ('Security', 74), ('grounds', 74), ('view', 74), ('19', 74), ('downward', 74), ('benefit', 74), ('offered', 74), ('Title', 74), ('justice', 73), ('knowledge', 73), ('failing', 73), ('27', 73), ('requested', 73), ('Law', 73), ('pled', 73), ('proposed', 73), ('appellate', 73), ('custody', 73), ('back', 73), ('robbery', 73), ('26', 73), ('took', 73), ('During', 72), ('control', 72), ('anything', 72), ('recognized', 72), ('possessed', 72), ('remedy', 72), ('reduce', 72), ('continued', 72), ('Leases', 72), ('ESI', 72), ('attempted', 71), ('total', 71), ('supported', 71), ('sexual', 71), ('contrary', 71), ('using', 71), ('22', 71), ('resulting', 71), ('felon', 71), ('change', 71), ('Gross', 71), ('third', 71), ('BR', 71), ('burglary', 71), ('Student', 71), ('Nebraska', 70), ('showing', 70), ('form', 70), ('members', 70), ('allegedly', 70), ('year', 70), ('neither', 70), ('revocation', 70), ('lllllllllllllllllllllDefendants', 70), ('documents', 70), ('life', 69), ('removed', 69), ('meet', 69), ('position', 69), ('1996', 69), ('seeking', 69), ('employees', 69), ('return', 69), ('Insurance', 69), ('education', 69), ('ERISA', 69), ('demonstrate', 68), ('calculation', 68), ('allege', 68), ('product', 68), ('statutes', 68), ('private', 68), ('every', 68), ('value', 68), ('personal', 68), ('interests', 68), ('behavior', 68), ('losses', 68), ('plans', 68), ('OPTN', 68), ('beyond', 67), ('nothing', 67), ('discussing', 67), ('protect', 67), ('effect', 67), ('Douglas', 67), ('witness', 67), ('discussed', 67), ('requirements', 67), ('service', 67), ('laws', 67), ('Restatement', 67), ('status', 67), ('acted', 67), ('Meza', 67), ('autism', 67), ('permission', 66), ('common', 66), ('written', 66), ('granting', 66), ('past', 66), ('ruling', 66), ('response', 66), ('procedural', 66), ('obligation', 66), ('pornography', 66), ('weapon', 66), ('ice', 66), ('retrieval', 66), ('Cuker', 66), ('showed', 65)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}